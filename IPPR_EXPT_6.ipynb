{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#IPPR EXPT 6\n",
        "\n",
        "##Experiment No.6\n",
        "\n",
        "###NAME - SWARNABH GAJBHIYE\n",
        "\n",
        "###PRN - 1032211392"
      ],
      "metadata": {
        "id": "q0TVguybjtzP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##AIM:\n",
        "To perform pattern recognition using CNN or similar ML approach"
      ],
      "metadata": {
        "id": "tqNITk-rj0dh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "##Algorithm:\n",
        "1. Load data from MNIST dataset which includes images of handwritten digits 0 to 9 of size\n",
        "28 x 28. [import mnist from keras.datasets]\n",
        "2. Split the data into train and test datasets.\n",
        "3. Pre-process the data to make sure the labels will be understandable by our CNN. MNIST\n",
        "dataset gives Labels as decimal values. For CNN we need to convert it to “one Hot\n",
        "Encoded” labels. [Use to_categorical function from keras.utils.np_utils]\n",
        "Convolution Layers for feature extraction\n",
        "\n",
        "4. Normalize the input data by dividing every input sample value by maximum value [255].\n",
        "5. Reshape train and test samples to include one more dimension to represent the number of\n",
        "channels. As MNIST data represents grey images number of channels is one.\n",
        "6. Set the CNN Model by selecting sequential model with Dense, Conv2D, MaxPool2D,\n",
        "Flatten layers.\n",
        "7. Add 2D convolution layer with 32 number of filters each of size 4x4, input image shape\n",
        "28 x 28 x 1 and activation function „Relu‟. [Use model.add]\n",
        "8. Similarly add MaxPool layer with size 2 x2, Flatten layer and two dense layers. In the last\n",
        "dense layer set 10 nodes to represent the 10 digits.\n",
        "9. Train the model using training samples and respective categorical labels. [use functions\n",
        "model.compile and model.fit]\n",
        "10. Evaluate the trained model using test dataset. [Use model.evaluate]\n",
        "11. Predict class of all the test samples and generate classification report."
      ],
      "metadata": {
        "id": "hBMQ6Fw7kVI3"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Result\n",
        "\n",
        "The implemented Convolutional Neural Network (CNN) achieved an accuracy of **X%** on the test dataset, indicating its effectiveness in recognizing handwritten digits from the MNIST dataset.\n",
        "\n",
        "## Conclusion\n",
        "\n",
        "The experiment successfully demonstrated the application of CNNs for pattern recognition tasks, specifically in recognizing handwritten digits. Through a systematic approach, the CNN model was constructed, trained, and evaluated using the MNIST dataset. The architecture comprised convolutional layers for feature extraction followed by dense layers for classification.\n",
        "\n",
        "The CNN's ability to learn hierarchical features directly from pixel values allowed it to achieve high accuracy in digit classification. The utilization of techniques such as one-hot encoding, normalization, and appropriate activation functions contributed to the model's performance.\n",
        "\n",
        "In conclusion, the experiment underscores the effectiveness of CNNs in pattern recognition tasks, highlighting their potential applications in various fields such as image recognition, medical diagnosis, and natural language processing. Further optimization and exploration of CNN architectures and hyperparameters could potentially enhance the model's performance even further.\n"
      ],
      "metadata": {
        "id": "7ZzNTwSFl3Bq"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "RiosFCssjshj"
      },
      "outputs": [],
      "source": [
        "# Import necessary libraries\n",
        "from keras.datasets import mnist\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 1: Load data from MNIST dataset\n",
        "(train_images, train_labels), (test_images, test_labels) = mnist.load_data()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mqPZtVAOkDgg",
        "outputId": "dd2a4138-3061-43cc-ce34-f07918eb9493"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/mnist.npz\n",
            "11490434/11490434 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 2: Split the data into train and test datasets\n",
        "\n",
        "# Step 3: Pre-process the data\n",
        "# Reshape and normalize the input data\n",
        "train_images = train_images.reshape((60000, 28, 28, 1)).astype('float32') / 255\n",
        "test_images = test_images.reshape((10000, 28, 28, 1)).astype('float32') / 255\n"
      ],
      "metadata": {
        "id": "XM8fE-Q-kIva"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert labels to one-hot encoded format\n",
        "train_labels = to_categorical(train_labels)\n",
        "test_labels = to_categorical(test_labels)\n"
      ],
      "metadata": {
        "id": "7FAjc23lkMvZ"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 4-8: Set CNN Model\n",
        "model = Sequential()\n",
        "model.add(Conv2D(32, (4, 4), activation='relu', input_shape=(28, 28, 1)))\n",
        "model.add(MaxPooling2D((2, 2)))\n",
        "model.add(Flatten())\n",
        "model.add(Dense(128, activation='relu'))\n",
        "model.add(Dense(10, activation='softmax'))\n"
      ],
      "metadata": {
        "id": "VgZXiYKnkQ9b"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 9: Train the model\n",
        "model.compile(optimizer='adam',\n",
        "              loss='categorical_crossentropy',\n",
        "              metrics=['accuracy'])\n",
        "model.fit(train_images, train_labels, epochs=5, batch_size=64, validation_split=0.2)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "r5Mi06eekbMo",
        "outputId": "5897c905-80f8-4a4c-a7b5-f9333ed56a4d"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "750/750 [==============================] - 32s 39ms/step - loss: 0.1921 - accuracy: 0.9450 - val_loss: 0.0750 - val_accuracy: 0.9773\n",
            "Epoch 2/5\n",
            "750/750 [==============================] - 26s 34ms/step - loss: 0.0623 - accuracy: 0.9814 - val_loss: 0.0641 - val_accuracy: 0.9811\n",
            "Epoch 3/5\n",
            "750/750 [==============================] - 27s 36ms/step - loss: 0.0397 - accuracy: 0.9875 - val_loss: 0.0566 - val_accuracy: 0.9839\n",
            "Epoch 4/5\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0294 - accuracy: 0.9903 - val_loss: 0.0569 - val_accuracy: 0.9841\n",
            "Epoch 5/5\n",
            "750/750 [==============================] - 24s 32ms/step - loss: 0.0206 - accuracy: 0.9934 - val_loss: 0.0474 - val_accuracy: 0.9866\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.History at 0x7c5b74f36590>"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 10: Evaluate the trained model\n",
        "test_loss, test_acc = model.evaluate(test_images, test_labels)\n",
        "print('Test accuracy:', test_acc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N2MscH3SkeM0",
        "outputId": "3eff5b0e-ef20-4145-d550-93574dc5cb4c"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 4s 11ms/step - loss: 0.0401 - accuracy: 0.9876\n",
            "Test accuracy: 0.9876000285148621\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Step 11: Predict class of all the test samples and generate classification report\n",
        "predictions = model.predict(test_images)\n",
        "predicted_labels = predictions.argmax(axis=1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8aMAql7lIFh",
        "outputId": "e6bc7c81-5340-4d82-e4f6-0fe185266a07"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "313/313 [==============================] - 2s 6ms/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(test_labels.argmax(axis=1), predicted_labels))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jWzlHjAglMBV",
        "outputId": "135d46db-2f63-407b-8c1c-36ae69cb4f87"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.99      0.99      0.99       980\n",
            "           1       0.99      1.00      0.99      1135\n",
            "           2       0.99      0.99      0.99      1032\n",
            "           3       0.98      0.99      0.99      1010\n",
            "           4       0.98      1.00      0.99       982\n",
            "           5       0.99      0.99      0.99       892\n",
            "           6       0.99      0.98      0.99       958\n",
            "           7       0.99      0.98      0.98      1028\n",
            "           8       0.98      0.99      0.98       974\n",
            "           9       0.99      0.97      0.98      1009\n",
            "\n",
            "    accuracy                           0.99     10000\n",
            "   macro avg       0.99      0.99      0.99     10000\n",
            "weighted avg       0.99      0.99      0.99     10000\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Post-lab questions:\n",
        "##Q.1 Draw the detailed architecture of generated CNN How many total number of trainable parameters are required for the implemented CNN."
      ],
      "metadata": {
        "id": "mR4os2uFlmAE"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "ANSWER =\n",
        "\n",
        "### Detailed Architecture of CNN\n",
        "\n",
        "1. **Input Layer:**\n",
        "   - Input shape: (28, 28, 1)\n",
        "\n",
        "2. **Convolutional Layer:**\n",
        "   - Filters: 32\n",
        "   - Kernel size: (4, 4)\n",
        "   - Activation function: ReLU\n",
        "   - Output shape: (25, 25, 32)  # Note: This depends on the choice of padding and stride.\n",
        "\n",
        "3. **Max Pooling Layer:**\n",
        "   - Pool size: (2, 2)\n",
        "   - Output shape: (12, 12, 32)  # Half the dimensions due to max pooling.\n",
        "\n",
        "4. **Flatten Layer:**\n",
        "   - Output shape: (4608)  # Flattens the 3D output to 1D for input to the dense layers.\n",
        "\n",
        "5. **Dense Layer:**\n",
        "   - Units: 128\n",
        "   - Activation function: ReLU\n",
        "\n",
        "6. **Output Layer:**\n",
        "   - Units: 10 (corresponding to the 10 digits)\n",
        "   - Activation function: Softmax\n",
        "\n",
        "### Total Number of Trainable Parameters\n",
        "\n",
        "1. **Convolutional Layer:**\n",
        "   - Parameters = (4 * 4 * 1 + 1) * 32 = 544\n",
        "   - Explanation: 4 * 4 * 1 (weights) + 1 (bias) per filter, times 32 filters.\n",
        "\n",
        "2. **Dense Layer:**\n",
        "   - Parameters = (4608 * 128 + 128) = 590,592\n",
        "   - Explanation: 4608 (input size) * 128 (units) + 128 (bias).\n",
        "\n",
        "3. **Output Layer:**\n",
        "   - Parameters = (128 * 10 + 10) = 1,290\n",
        "   - Explanation: 128 (input size) * 10 (units) + 10 (bias).\n",
        "\n",
        "**Total Trainable Parameters:**\n",
        "   - Total = 544 + 590,592 + 1,290 = 592,426\n"
      ],
      "metadata": {
        "id": "7XGGN-Xklql0"
      }
    }
  ]
}